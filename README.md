# Autonomous safety evaluation & rescue for subterranean confined spaces

## Get started

Clone this repo by running the following:

`git clone https://github.com/pbjames/evacbot`

or use the SSH link generated by GitHub if that's how you're authenticated.

Open webots and go to `File / Open World...` and select the world at
`evacbot/worlds/default.wbt`. Now webots should open this project by default when
started.

## Evaluation

### Considerations

It's difficult to simulate everything accurately so we will focus on accurate and
efficient approximations for the environment. Think of how we could potentially extend
and build on the principles of what we are testing in a serious, commercial environment.

In particular, I think we should focus on simulating many different kinds of environment
with different kinds of hazards and obstructions for the robot to navigate through. This
should help also facilitate any machine learning algorithms we use, for example in
computer vision.

### Modelling the environment

I'll get started building an environment and try to lead by example on this one. There
are tutorials for building simulations [here](https://cyberbotics.com/doc/guide/tutorial-1-your-first-simulation-in-webots?tab-language=python).

## Goals

- Reproducible mappings of the environment can be made which sufficiently communicates
  the risks to human life in an enclosed space.
- Our robot should work correctly in natural, urban and industrial environments.
- Navigation is efficient, detailed and doesn't put the robot in harm's way
- Our robot still works in previously unseen environments

## Approach

### Pathing

Using the A\* algorithm in combination with appropriate movement methods and hazard
identification & localisation will calculate optimal traversal of the space.

This will be done by constructing a node graph of space using mappings and assigning
relative weights based on actual calculated distance between nodes. Nodes near hazardous
objects or sources will have a higher weight. Nodes with the most empty space and no
local hazards will be the lowest weighted.

The algorithm will continually update the node graph and traverse safely in order to be
reactive to dynamic situations.

### SLAM - Tamryn Haque

We wish to perform 3-dimensional SLAM in potentially hazardous areas. Through use of the Mavic 2 Pro drone with additional sensors, such as the Velodyne VLP-16 LiDAR.

Our system will make use of the SLAM algorithm LIO-SAM, which combines LiDAR data and IMU data for accurate and smooth localization. LiDAR provides geometric features and the IMU provides motion updates. LIO-SAM combines them through non-linear optimization, producing low-drift trajectory and a clean 3D map of the environment.

This sensor set-up and algorithm together allow the drone to fly, localize, and map reliably in potentially dark, GPS-denied environment.

### Hazard Identification
We will focus on designing and integrating the danger detection system, allowing the drone to identify environmental hazards such as fire, toxic gases, and physical obstacles that influence navigation and safety decisions.

We use a YOLOv8 object detector trained to output bounding boxes and confidence scores for fire (and optionally smoke) and onboard sensing (camera, LiDAR/depth, and a simulated gas sensor) and SLAM-based localisation, detected hazards are mapped into a 3D risk layer of the environment. This risk map is then fed into path planning (e.g., A*), where areas near hazards are assigned higher traversal cost or marked as no-go zones, allowing the drone to continuously re-plan safer routes in dark, GPS-denied, and previously unseen subterranean spaces.
